{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import remove_small_objects, skeletonize\n",
    "from skimage.measure import label\n",
    "from skan import Skeleton, summarize\n",
    "from sim_class import Simulation\n",
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "from ot2_gym_wrapper_team import OT2_wrapper\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from patchify import patchify, unpatchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = OT2_wrapper(render=False, max_steps=1000, accuracy_threshold=0.001)\n",
    "obs, info = env.reset()\n",
    "sim = env.sim # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = sim.get_plate_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all plate images...\n",
      "Image 0 saved to processed_images\\image_0.png\n",
      "Image 1 saved to processed_images\\image_1.png\n",
      "Image 2 saved to processed_images\\image_2.png\n",
      "Image 3 saved to processed_images\\image_3.png\n",
      "Image 4 saved to processed_images\\image_4.png\n",
      "Image 5 saved to processed_images\\image_5.png\n",
      "Image 6 saved to processed_images\\image_6.png\n",
      "Image 7 saved to processed_images\\image_7.png\n",
      "Image 8 saved to processed_images\\image_8.png\n",
      "Image 9 saved to processed_images\\image_9.png\n",
      "All images processed!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the environment\n",
    "env = OT2_wrapper(render=False, max_steps=1000, accuracy_threshold=0.001)\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Access the simulation instance\n",
    "sim = env.sim\n",
    "\n",
    "# Function to process and display each image\n",
    "def process_image(image_path, save_dir, index):\n",
    "    # Load the image in grayscale mode\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Validate if the image is loaded correctly\n",
    "    if image is None:\n",
    "        print(f\"Failed to load the image from the path: {image_path}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # Save the original grayscale image for further processing\n",
    "    output_path = os.path.join(save_dir, f\"image_{index}.png\")\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Image {index} saved to {output_path}\")\n",
    "\n",
    "# Directory to save the cropped and padded images\n",
    "save_directory = \"processed_images\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Loop through all images\n",
    "print(\"Processing all plate images...\")\n",
    "for i in range(10):  # Replace 10 with the actual number of images you want to process\n",
    "    try:\n",
    "        # Retrieve the image path\n",
    "        image_path = sim.get_plate_image()\n",
    "        process_image(image_path, save_directory, i)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {i}: {e}\")\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "print(\"All images processed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all plate images...\n",
      "Image 0 saved to processed_images\\image_0.png\n",
      "Processed image_0: Original shape (3006, 4202), Padded shape (2816, 2816), Patches (12, 12, 256, 256)\n",
      "Image 1 saved to processed_images\\image_1.png\n",
      "Processed image_1: Original shape (3006, 4202), Padded shape (2816, 2816), Patches (12, 12, 256, 256)\n",
      "Image 2 saved to processed_images\\image_2.png\n",
      "Processed image_2: Original shape (3006, 4202), Padded shape (2816, 2816), Patches (12, 12, 256, 256)\n",
      "Image 3 saved to processed_images\\image_3.png\n",
      "Processed image_3: Original shape (3006, 4202), Padded shape (2816, 2816), Patches (12, 12, 256, 256)\n",
      "Image 4 saved to processed_images\\image_4.png\n",
      "Processed image_4: Original shape (3006, 4202), Padded shape (2816, 2816), Patches (12, 12, 256, 256)\n",
      "Image 5 saved to processed_images\\image_5.png\n",
      "Processed image_5: Original shape (3006, 4202), Padded shape (2816, 2816), Patches (12, 12, 256, 256)\n",
      "Image 6 saved to processed_images\\image_6.png\n",
      "Processed image_6: Original shape (3006, 4202), Padded shape (2816, 2816), Patches (12, 12, 256, 256)\n",
      "Image 7 saved to processed_images\\image_7.png\n",
      "Processed image_7: Original shape (3006, 4202), Padded shape (2816, 2816), Patches (12, 12, 256, 256)\n",
      "Image 8 saved to processed_images\\image_8.png\n",
      "Processed image_8: Original shape (3006, 4202), Padded shape (2816, 2816), Patches (12, 12, 256, 256)\n",
      "Image 9 saved to processed_images\\image_9.png\n",
      "Processed image_9: Original shape (3006, 4202), Padded shape (2816, 2816), Patches (12, 12, 256, 256)\n",
      "Total images processed: 10\n"
     ]
    }
   ],
   "source": [
    "# Initialize the environment\n",
    "env = OT2_wrapper(render=False, max_steps=1000, accuracy_threshold=0.001)\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Access the simulation instance\n",
    "sim = env.sim\n",
    "\n",
    "# Directory to save the processed images\n",
    "save_directory = \"processed_images\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Function to process and save each image\n",
    "def process_and_save_image(image_path, save_dir, index):\n",
    "    \"\"\"\n",
    "    Load, validate, and save an image from the given path.\n",
    "    \"\"\"\n",
    "    # Load the image in grayscale mode\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Validate if the image is loaded correctly\n",
    "    if image is None:\n",
    "        print(f\"Failed to load the image from the path: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    # Save the grayscale image for further processing\n",
    "    output_path = os.path.join(save_dir, f\"image_{index}.png\")\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Image {index} saved to {output_path}\")\n",
    "\n",
    "    return image\n",
    "\n",
    "# Preprocessing helper functions\n",
    "def detect_edges(image, max_size=2800):\n",
    "    \"\"\"\n",
    "    Detect edges and find the approximate square Petri dish.\n",
    "    \"\"\"\n",
    "    blurred_image = cv2.GaussianBlur(image, (51, 51), 0)\n",
    "    sobel_x = cv2.Sobel(blurred_image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobel_y = cv2.Sobel(blurred_image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    gradient_magnitude = cv2.magnitude(sobel_x, sobel_y)\n",
    "    _, edges = cv2.threshold(gradient_magnitude, 50, 255, cv2.THRESH_BINARY)\n",
    "    edges = edges.astype(np.uint8)\n",
    "\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "\n",
    "    side_length = min(max(w, h), max_size)\n",
    "    center_x, center_y = x + w // 2, y + h // 2\n",
    "    half_side = side_length // 2\n",
    "    new_x = max(center_x - half_side, 0)\n",
    "    new_y = max(center_y - half_side, 0)\n",
    "    new_w = new_h = min(side_length, min(image.shape[1] - new_x, image.shape[0] - new_y))\n",
    "    return new_x, new_x + new_w, new_y, new_y + new_h\n",
    "\n",
    "def crop_image(image, edges):\n",
    "    \"\"\"\n",
    "    Crop the image based on detected edges.\n",
    "    \"\"\"\n",
    "    left, right, top, bottom = edges\n",
    "    return image[top:bottom, left:right]\n",
    "\n",
    "def padder(image, patch_size=256):\n",
    "    \"\"\"\n",
    "    Add padding to make dimensions divisible by the patch size.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    height_padding = ((h // patch_size) + 1) * patch_size - h\n",
    "    width_padding = ((w // patch_size) + 1) * patch_size - w\n",
    "    top_padding = int(height_padding / 2)\n",
    "    bottom_padding = height_padding - top_padding\n",
    "    left_padding = int(width_padding / 2)\n",
    "    right_padding = width_padding - left_padding\n",
    "    return cv2.copyMakeBorder(image, top_padding, bottom_padding, left_padding, right_padding, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "def preprocess_image(image, patch_size=256):\n",
    "    \"\"\"\n",
    "    Preprocess the image: pad, patchify, and normalize.\n",
    "    \"\"\"\n",
    "    padded_image = padder(image, patch_size)\n",
    "    patches = patchify(padded_image, (patch_size, patch_size), step=patch_size)\n",
    "    patches_reshaped = patches.reshape(-1, patch_size, patch_size, 1)  # Add channel dimension\n",
    "    patches_normalized = patches_reshaped / 255.0\n",
    "    return patches, patches_normalized\n",
    "\n",
    "# Process all images and apply preprocessing\n",
    "print(\"Processing all plate images...\")\n",
    "preprocessed_data = []\n",
    "patch_size = 256\n",
    "\n",
    "for i in range(10):  # Adjust range as needed\n",
    "    try:\n",
    "        # Retrieve the image path from the simulation\n",
    "        image_path = sim.get_plate_image()\n",
    "\n",
    "        # Process and save the image\n",
    "        image = process_and_save_image(image_path, save_directory, i)\n",
    "\n",
    "        if image is not None:\n",
    "            # Apply preprocessing\n",
    "            edges = detect_edges(image)\n",
    "            cropped_image = crop_image(image, edges)\n",
    "            padded_image = padder(cropped_image, patch_size)\n",
    "            patches, patches_normalized = preprocess_image(padded_image, patch_size)\n",
    "\n",
    "            preprocessed_data.append((f\"image_{i}\", patches_normalized))\n",
    "\n",
    "            # Print progress\n",
    "            print(f\"Processed image_{i}: Original shape {image.shape}, \"\n",
    "                  f\"Padded shape {padded_image.shape}, Patches {patches.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {i}: {e}\")\n",
    "\n",
    "print(f\"Total images processed: {len(preprocessed_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown metric function: f1. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\35988\\anaconda3\\envs\\Block_b_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\35988\\anaconda3\\envs\\Block_b_GPU\\lib\\site-packages\\keras\\utils\\generic_utils.py:769\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    767\u001b[0m     obj \u001b[38;5;241m=\u001b[39m module_objects\u001b[38;5;241m.\u001b[39mget(object_name)\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    770\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprintable_module_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    771\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure this object is passed to the `custom_objects` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    772\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    773\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    774\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#registering_the_custom_object for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    775\u001b[0m         )\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;66;03m# returned as-is.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_inspect\u001b[38;5;241m.\u001b[39misclass(obj):\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown metric function: f1. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "model_path = \"model.h5\"\n",
    "model = load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 41ms/step\n",
      "Predicted patches shape for image_0: (144, 256, 256, 1)\n",
      "Error processing image_0: cannot select an axis to squeeze out which has size not equal to one\n",
      "9/9 [==============================] - 0s 42ms/step\n",
      "Predicted patches shape for image_1: (144, 256, 256, 1)\n",
      "Error processing image_1: cannot select an axis to squeeze out which has size not equal to one\n",
      "9/9 [==============================] - 0s 50ms/step\n",
      "Predicted patches shape for image_2: (144, 256, 256, 1)\n",
      "Error processing image_2: cannot select an axis to squeeze out which has size not equal to one\n",
      "9/9 [==============================] - 0s 39ms/step\n",
      "Predicted patches shape for image_3: (144, 256, 256, 1)\n",
      "Error processing image_3: cannot select an axis to squeeze out which has size not equal to one\n",
      "9/9 [==============================] - 0s 39ms/step\n",
      "Predicted patches shape for image_4: (144, 256, 256, 1)\n",
      "Error processing image_4: cannot select an axis to squeeze out which has size not equal to one\n",
      "9/9 [==============================] - 0s 40ms/step\n",
      "Predicted patches shape for image_5: (144, 256, 256, 1)\n",
      "Error processing image_5: cannot select an axis to squeeze out which has size not equal to one\n",
      "9/9 [==============================] - 1s 82ms/step\n",
      "Predicted patches shape for image_6: (144, 256, 256, 1)\n",
      "Error processing image_6: cannot select an axis to squeeze out which has size not equal to one\n",
      "9/9 [==============================] - 0s 41ms/step\n",
      "Predicted patches shape for image_7: (144, 256, 256, 1)\n",
      "Error processing image_7: cannot select an axis to squeeze out which has size not equal to one\n",
      "9/9 [==============================] - 0s 40ms/step\n",
      "Predicted patches shape for image_8: (144, 256, 256, 1)\n",
      "Error processing image_8: cannot select an axis to squeeze out which has size not equal to one\n",
      "9/9 [==============================] - 0s 42ms/step\n",
      "Predicted patches shape for image_9: (144, 256, 256, 1)\n",
      "Error processing image_9: cannot select an axis to squeeze out which has size not equal to one\n"
     ]
    }
   ],
   "source": [
    "# **Run predictions**\n",
    "predictions = []\n",
    "patch_size = 256  # Assuming patches are 256x256 as specified in preprocessing\n",
    "\n",
    "for filename, patches_normalized in preprocessed_data:\n",
    "    try:\n",
    "        # Predict on patches\n",
    "        predicted_patches = model.predict(patches_normalized, batch_size=16)\n",
    "\n",
    "        # Inspect the shape of predicted patches\n",
    "        print(f\"Predicted patches shape for {filename}: {predicted_patches.shape}\")\n",
    "\n",
    "        # Reshape predictions back to grid dimensions (num_patches_y, num_patches_x, patch_size, patch_size)\n",
    "        num_patches_y, num_patches_x = 12, 12  # Replace with actual grid dimensions if dynamic\n",
    "        predicted_patches = predicted_patches.reshape((num_patches_y, num_patches_x, patch_size, patch_size))\n",
    "\n",
    "        # Drop the last channel dimension (if single channel output)\n",
    "        predicted_patches = np.squeeze(predicted_patches, axis=-1)\n",
    "\n",
    "        # Reconstruct the full image using unpatchify\n",
    "        petri_dish_padded_shape = (num_patches_y * patch_size, num_patches_x * patch_size)\n",
    "        reconstructed_prediction = unpatchify(predicted_patches, petri_dish_padded_shape)\n",
    "\n",
    "        # Store the prediction\n",
    "        predictions.append((filename, reconstructed_prediction))\n",
    "        print(f\"Prediction completed for {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "# **Visualize predictions**\n",
    "for filename, predicted_mask in predictions:\n",
    "    plt.figure(dpi=100)\n",
    "    plt.imshow(predicted_mask, cmap='gray')\n",
    "    plt.title(f\"Prediction for {filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(predicted_patches.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Block_b_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
